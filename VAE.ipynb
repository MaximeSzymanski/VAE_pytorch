{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MaximeSzymanski/VAE_pytorch/blob/main/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wO1VFuW2uNGJ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:22.829206Z",
     "start_time": "2023-10-30T11:13:21.365912Z"
    },
    "collapsed": true,
    "id": "3TMoxB50sg5D",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# get mnist data\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/VAE_pytorch/venv/lib/python3.9/site-packages/torch/__init__.py:465\u001B[0m\n\u001B[1;32m    451\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(textwrap\u001B[38;5;241m.\u001B[39mdedent(\u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;124m            Failed to load PyTorch C extensions:\u001B[39m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;124m                or by running Python from a different directory.\u001B[39m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;124m            \u001B[39m\u001B[38;5;124m'''\u001B[39m)\u001B[38;5;241m.\u001B[39mstrip()) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    463\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m  \u001B[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001B[39;00m\n\u001B[0;32m--> 465\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mdir\u001B[39m(\u001B[43m_C\u001B[49m):\n\u001B[1;32m    466\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m name\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBase\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    467\u001B[0m         __all__\u001B[38;5;241m.\u001B[39mappend(name)\n",
      "\u001B[0;31mNameError\u001B[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# get mnist data\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:22.877593Z",
     "start_time": "2023-10-30T11:13:22.830870Z"
    },
    "id": "v2Zexnqssg5F"
   },
   "outputs": [],
   "source": [
    "# get mnist data and transform to tensor, to the right device.\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "\"\"\"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\"\"\"\n",
    "device = 'cpu'\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.271993Z",
     "start_time": "2023-10-30T11:13:22.878786Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "x1EoFsKAsg5F",
    "outputId": "43faab69-c3f0-412d-c0b7-a28d2c034aaa"
   },
   "outputs": [],
   "source": [
    "# plot 10 images\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(mnist_trainset[i][0].numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title(mnist_trainset[i][1])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.355150Z",
     "start_time": "2023-10-30T11:13:23.273151Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "WAnWhy6rsg5F",
    "outputId": "d2d700ac-c863-4ba2-ee92-0511adefa559"
   },
   "outputs": [],
   "source": [
    "# plot the distribution of labels, with one color for each label\n",
    "labels = mnist_trainset.targets.numpy()\n",
    "plt.hist(labels, bins=np.arange(labels.min(), labels.max()+1))\n",
    "plt.xticks(np.arange(labels.min(), labels.max()+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.460793Z",
     "start_time": "2023-10-30T11:13:23.362911Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "NQd5v21r4aCm",
    "outputId": "31c0583a-e03f-4627-a4da-fbb42ba942b8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    }
   },
   "outputs": [],
   "source": [
    "# remove half of the 9s from the training set, to have a more balanced dataset\n",
    "# we will use this dataset to train the encoder\n",
    "# get the indices of the 9s\n",
    "nines = np.where(labels==9)[0]\n",
    "# shuffle the indices\n",
    "np.random.shuffle(nines)\n",
    "# keep only half of the indices\n",
    "nines = nines[:len(nines)//2]\n",
    "# remove the 9s from the training set\n",
    "mnist_trainset.data = torch.cat([mnist_trainset.data[labels!=9], mnist_trainset.data[nines]])\n",
    "mnist_trainset.targets = torch.cat([mnist_trainset.targets[labels!=9], mnist_trainset.targets[nines]])\n",
    "\n",
    "# plot the distribution of labels, with one color for each label\n",
    "labels = mnist_trainset.targets.numpy()\n",
    "plt.hist(labels, bins=np.arange(labels.min(), labels.max()+1))\n",
    "plt.xticks(np.arange(labels.min(), labels.max()+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.466799Z",
     "start_time": "2023-10-30T11:13:23.463685Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "Ci9Lkp1w4aCn",
    "outputId": "adbcc780-e111-4652-c20a-7de0487ddefc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# keep only percentage of the training set\n",
    "percentage = 0.01\n",
    "mnist_trainset.data = mnist_trainset.data[:int(len(mnist_trainset.data)*percentage)]\n",
    "mnist_trainset.targets = mnist_trainset.targets[:int(len(mnist_trainset.targets)*percentage)]\n",
    "mnist_testset.data = mnist_testset.data[:int(len(mnist_testset.data)*percentage)]\n",
    "mnist_testset.targets = mnist_testset.targets[:int(len(mnist_testset.targets)*percentage)]\n",
    "print(f\"Number of images in the training set: {len(mnist_trainset)}\")\n",
    "print(f\"Number of images in the test set: {len(mnist_testset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.473003Z",
     "start_time": "2023-10-30T11:13:23.470501Z"
    },
    "id": "ZK-BqssRsg5F"
   },
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        # relu\n",
    "        # pooling\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        # relu\n",
    "        # pooling\n",
    "        # flatten\n",
    "        self.fc1 = torch.nn.Linear(64*7*7, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: batch_size * 1 * 28 * 28\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        # x: batch_size * 32 * 28 * 28\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        # x: batch_size * 64 * 28 * 28\n",
    "        # flatten\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        # x: batch_size * 64*7*7\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        # x: batch_size * hidden_dim\n",
    "        x = self.fc2(x)\n",
    "        # x: batch_size * latent_dim\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.524945Z",
     "start_time": "2023-10-30T11:13:23.476583Z"
    },
    "id": "2RwboX70sg5F"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(1, 128, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.525351Z",
     "start_time": "2023-10-30T11:13:23.481950Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db1vIK9qsg5F",
    "outputId": "08a91575-4b52-440d-9f4c-e1b7e145c0ac"
   },
   "outputs": [],
   "source": [
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.765368Z",
     "start_time": "2023-10-30T11:13:23.487782Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "gUGjy1WSsg5G",
    "outputId": "993cda38-9477-4e99-d369-3febe4f885a5"
   },
   "outputs": [],
   "source": [
    "# encode the first 10 images\n",
    "images = mnist_trainset.data.float().unsqueeze(1)\n",
    "encoder(images)\n",
    "# plot the encoded images in 2D\n",
    "encoded_images = encoder(images).detach().numpy()\n",
    "plt.scatter(encoded_images[:, 0], encoded_images[:, 1], c=mnist_trainset.targets.numpy())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.774125Z",
     "start_time": "2023-10-30T11:13:23.772243Z"
    },
    "id": "sUPlfy3csg5G"
   },
   "outputs": [],
   "source": [
    "class SamplingLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SamplingLayer, self).__init__()\n",
    "\n",
    "    def forward(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "class VariationalEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(8)  # Batch Normalization after the first convolution\n",
    "        self.conv2 = torch.nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(16)  # Batch Normalization after the second convolution\n",
    "        self.conv3 = torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(32)  # Batch Normalization after the third convolution\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(512, hidden_dim)\n",
    "        self.mu = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        self.logvar = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        self.sampling = SamplingLayer()\n",
    "        # init logvar to 0\n",
    "        self.logvar.weight.data.fill_(0)\n",
    "        self.logvar.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        original_x = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  # Apply Batch Normalization\n",
    "        x = torch.nn.functional.leaky_relu(x, 0.2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)  # Apply Batch Normalization\n",
    "        x = torch.nn.functional.leaky_relu(x, 0.2)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)  # Apply Batch Normalization\n",
    "        x = torch.nn.functional.leaky_relu(x, 0.2)\n",
    "\n",
    "        x = torch.nn.Flatten(start_dim=1)(x)\n",
    "        # x: batch_size * 64*7*7\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        # x: batch_size * hidden_dim\n",
    "        mu = self.mu(x)\n",
    "        sigma = self.logvar(x)\n",
    "        z = self.sampling(mu, sigma)\n",
    "        # print the shape\n",
    "        \"\"\"print(f'original_x: {original_x.shape}')\n",
    "        print(f'mu: {mu.shape}')\n",
    "        print(f'sigma: {sigma.shape}')\n",
    "        print(f'z: {z.shape}')\"\"\"\n",
    "\n",
    "        # x: batch_size * latent_dim\n",
    "        return z, mu, sigma, original_x\n",
    "\n",
    "class VariationalDecoder(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(VariationalDecoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.fc1 = torch.nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 3 * 3 * 32)\n",
    "\n",
    "        # Transpose Convolutional layers\n",
    "        self.t_conv1 = torch.nn.ConvTranspose2d(32, 16, kernel_size=7, stride=2, padding=0)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(16)  # Batch Normalization after the first transposed convolution\n",
    "        self.t_conv2 = torch.nn.ConvTranspose2d(16, 8, kernel_size=7, stride=2, padding=0)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(8)  # Batch Normalization after the second transposed convolution\n",
    "        self.t_conv3 = torch.nn.ConvTranspose2d(8, 1, kernel_size=4, stride=1, padding=1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.leaky_relu(x, 0.2)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x, 0.2)\n",
    "        x = torch.nn.Unflatten(1, (32, 3, 3))(x)\n",
    "        x = self.t_conv1(x)\n",
    "        x = self.bn1(x)  # Apply Batch Normalization\n",
    "        x = torch.nn.functional.leaky_relu(x, 0.2)\n",
    "        x = self.t_conv2(x)\n",
    "        x = self.bn2(x)  # Apply Batch Normalization\n",
    "        x = torch.nn.functional.leaky_relu(x, 0.2)\n",
    "        x = self.t_conv3(x)\n",
    "        x = torch.nn.functional.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.778617Z",
     "start_time": "2023-10-30T11:13:23.775819Z"
    },
    "id": "uPF_bR_Nsg5G"
   },
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        self.encoder = VariationalEncoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = VariationalDecoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, sigma, original_x = self.encoder(x)\n",
    "        x = self.decoder(z)\n",
    "        return x, mu, sigma, original_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.781729Z",
     "start_time": "2023-10-30T11:13:23.780095Z"
    },
    "id": "ul4LSaBTsg5G"
   },
   "outputs": [],
   "source": [
    "def KL_loss(mu, sigma):\n",
    "    return -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n",
    "\n",
    "def reconstruction_loss(original_x, x):\n",
    "\n",
    "\n",
    "    return torch.nn.functional.binary_cross_entropy(x, original_x, reduction='sum')\n",
    "\n",
    "def loss_function(x, original_x, mu, sigma,k1=1,k2=1e-4):\n",
    "\n",
    "    return k1 *reconstruction_loss(original_x, x) + k2 * KL_loss(mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.818768Z",
     "start_time": "2023-10-30T11:13:23.784500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rWg0DCEsg5H",
    "outputId": "c09ab96f-22e4-4c99-8e9e-e702528060a2"
   },
   "outputs": [],
   "source": [
    "\n",
    "variational_autoencoder = VariationalAutoEncoder(1, 128, 64)\n",
    "variational_autoencoder.to(device)\n",
    "print(variational_autoencoder.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.954067Z",
     "start_time": "2023-10-30T11:13:23.790340Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "bONBAHbmsg5G",
    "outputId": "0acd1e06-788c-4044-f6bb-b4b295c7dc2d"
   },
   "outputs": [],
   "source": [
    "# encode the first 10 images\n",
    "images = mnist_trainset.data[1].float().unsqueeze(0).unsqueeze(1)\n",
    "images = images.to(device)\n",
    "\n",
    "encoded,_,_,_= variational_autoencoder.encoder(images)\n",
    "decoded = variational_autoencoder.decoder(encoded)\n",
    "\n",
    "# plot the original image, and the decoded images\n",
    "plt.imshow(images[0, 0].cpu().detach().numpy())\n",
    "# add title\n",
    "plt.title(\"original image\")\n",
    "plt.show()\n",
    "encoded_images = encoded.cpu().detach().numpy()\n",
    "plt.imshow(decoded[0, 0].cpu().detach().numpy())\n",
    "plt.title(\"decoded image\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.959578Z",
     "start_time": "2023-10-30T11:13:23.955346Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGWqhxxtsg5H",
    "outputId": "dd6e0825-36e6-42c7-9bfa-30d854088aef"
   },
   "outputs": [],
   "source": [
    "print(variational_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.961960Z",
     "start_time": "2023-10-30T11:13:23.960210Z"
    },
    "id": "BJ2uR1aBsg5H"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "epochs = 10\n",
    "optimizer = torch.optim.Adam(variational_autoencoder.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:23.966085Z",
     "start_time": "2023-10-30T11:13:23.963112Z"
    },
    "id": "yGchFGa7sg5H"
   },
   "outputs": [],
   "source": [
    "\n",
    "# take inly 10 images\n",
    "#mnist_trainset.data = mnist_trainset.data[:nb_image_to_overfit]\n",
    "#mnist_trainset.targets = mnist_trainset.targets[:nb_image_to_overfit]\n",
    "\n",
    "# shuffle the data and the targets in the same way\n",
    "indices = torch.randperm(len(mnist_trainset.data))\n",
    "mnist_trainset.data = mnist_trainset.data[indices]\n",
    "mnist_trainset.targets = mnist_trainset.targets[indices]\n",
    "\n",
    "mnist_trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:26.280528Z",
     "start_time": "2023-10-30T11:13:23.967846Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "qESrXEni4aCp",
    "outputId": "59df19dc-7554-42d4-8013-b45169a3cc38",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    }
   },
   "outputs": [],
   "source": [
    "# check clusters using t-sne\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "with torch.no_grad():\n",
    "    images = mnist_trainset.data.float().unsqueeze(1)\n",
    "    images = images.to(device)\n",
    "    encoded = variational_autoencoder.encoder(images)\n",
    "    decoded = variational_autoencoder.decoder(encoded[0])\n",
    "\n",
    "    # Plot the encoded images in 2D and use contrasting colors\n",
    "    encoded_images = encoded[0].cpu().detach().numpy()\n",
    "\n",
    "encoded_data_2d = TSNE(n_components=2).fit_transform(encoded_images)\n",
    "sns.scatterplot(x=encoded_data_2d[:, 0], y=encoded_data_2d[:, 1], hue=mnist_trainset.targets.numpy(), legend='full', palette=sns.color_palette(\"hls\", 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:26.286289Z",
     "start_time": "2023-10-30T11:13:26.282394Z"
    },
    "id": "M8bZ-nEKsg5H"
   },
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for i, (images, _) in enumerate(mnist_trainloader):\n",
    "            # plot the first image of the first batch\n",
    "\n",
    "            # check if images is full of 0\n",
    "            images = images.float()\n",
    "            # count number of non 0 in the tensor\n",
    "\n",
    "\n",
    "            images = images.to(device)\n",
    "            x, mu, sigma, original_x = variational_autoencoder(images)\n",
    "            original_x = original_x.detach()\n",
    "            loss = loss_function(x, original_x, mu, sigma)\n",
    "\n",
    "            epoch_loss += loss.mean().item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch: {epoch+1}, Loss: {epoch_loss/len(mnist_trainloader.dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:28.893790Z",
     "start_time": "2023-10-30T11:13:26.285251Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APl-4tyqsg5H",
    "outputId": "2c3f7ac2-5947-4b11-9ef2-142c61d919a6"
   },
   "outputs": [],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:29.022483Z",
     "start_time": "2023-10-30T11:13:28.895633Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "9dkQ622dsg5H",
    "outputId": "53f28358-c53b-4cae-e69c-6acbc6c9ef1f"
   },
   "outputs": [],
   "source": [
    "# take all images from the train set\n",
    "with torch.no_grad():\n",
    "  # encode the first 10 images\n",
    "    print(mnist_trainset.data.shape)\n",
    "    images = mnist_trainset.data.float().unsqueeze(1)\n",
    "    images = images.to(device)\n",
    "    # plot the encoded images in 2D\n",
    "\n",
    "    encoded_images, _ , _ ,_  = variational_autoencoder.encoder(images)\n",
    "    encoded_images = encoded_images.cpu().detach().numpy()\n",
    "    plt.scatter(encoded_images[:, 0], encoded_images[:, 1], c=mnist_trainset.targets.numpy())\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:30.071884Z",
     "start_time": "2023-10-30T11:13:29.028794Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wGiR7vwfsg5H",
    "outputId": "b8cfe834-f11a-42d5-aa15-c71cf3b80a67"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Take 10 images from the train set\n",
    "with torch.no_grad():\n",
    "    images = mnist_trainset.data.float().unsqueeze(1)\n",
    "    images = images.to(device)\n",
    "    encoded = variational_autoencoder.encoder(images)\n",
    "\n",
    "    # Plot the encoded images in 2D and use contrasting colors\n",
    "    encoded_images = encoded[0].cpu().detach().numpy()\n",
    "    c = mnist_trainset.targets.numpy()\n",
    "    f, ax_arr = plt.subplots(1, 2)\n",
    "    ax_arr[0].scatter(encoded_images[:, 0], encoded_images[:, 1], c=c)\n",
    "    ax_arr[0].set_title('Encoded images')\n",
    "\n",
    "    images_test = mnist_testset.data.float().unsqueeze(1)\n",
    "    images_test = images_test.to(device)\n",
    "    encoded = variational_autoencoder.encoder(images_test)\n",
    "\n",
    "    # Plot the encoded images in 2D and use contrasting colors\n",
    "    encoded_images = encoded[0].cpu().detach().numpy()\n",
    "    c = mnist_testset.targets.numpy()\n",
    "\n",
    "    ax_arr[1].scatter(encoded_images[:, 0], encoded_images[:, 1], c=c)\n",
    "    ax_arr[1].set_title('Encoded images test')\n",
    "\n",
    "    # Plot the decoded images in a 2 by 5 grid, with the original images on top of each decoded image\n",
    "    f, axarr = plt.subplots(2, 10)\n",
    "\n",
    "    # Get the first 10 images\n",
    "    random_images_train = mnist_trainset.data[:10].float().unsqueeze(1)\n",
    "    random_images_train = random_images_train.to(device)\n",
    "    # Encode the whole images\n",
    "    encoded_train, _, _, _ = variational_autoencoder.encoder(random_images_train)\n",
    "\n",
    "    decoded_train = variational_autoencoder.decoder(encoded_train)\n",
    "    # Decode the whole images and plot them\n",
    "    axarr[0, 0].set_title('Train reconstructions')\n",
    "\n",
    "    for i in range(10):\n",
    "        # Remove the axis ticks\n",
    "        axarr[0, i].axis('off')\n",
    "        axarr[1, i].axis('off')\n",
    "        # name it train\n",
    "        # Plot the original images in black and white\n",
    "        axarr[0, i].imshow(random_images_train[i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "\n",
    "        axarr[1, i].imshow(decoded_train[i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "\n",
    "\n",
    "    # Do the same for the test set\n",
    "    random_images_test = mnist_testset.data[:10].float().unsqueeze(1)\n",
    "    random_images_test = random_images_test.to(device)\n",
    "    # Encode the whole test images\n",
    "    encoded_test, _, _, _ = variational_autoencoder.encoder(random_images_test)\n",
    "\n",
    "    # Decode the test images\n",
    "    decoded_test = variational_autoencoder.decoder(encoded_test)\n",
    "\n",
    "    # Plot the decoded test images\n",
    "    f, axarr = plt.subplots(2, 10)\n",
    "    axarr[0, 0].set_title('Test reconstructions')\n",
    "\n",
    "    for i in range(10):\n",
    "        # Remove the axis ticks\n",
    "        axarr[0, i].axis('off')\n",
    "        axarr[1, i].axis('off')\n",
    "\n",
    "        # Plot the original images in black and white\n",
    "        axarr[0, i].imshow(random_images_test[i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "\n",
    "        axarr[1, i].imshow(decoded_test[i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:30.219929Z",
     "start_time": "2023-10-30T11:13:30.073650Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "ISaEyuqV4aCq",
    "outputId": "4e20d5e7-43f0-48f9-bd53-fbe080a5192d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    }
   },
   "outputs": [],
   "source": [
    "# check clusters using t-sne\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "with torch.no_grad():\n",
    "    images = mnist_testset.data.float().unsqueeze(1)\n",
    "    images = images.to(device)\n",
    "    encoded = variational_autoencoder.encoder(images)\n",
    "    decoded = variational_autoencoder.decoder(encoded[0])\n",
    "\n",
    "    # Plot the encoded images in 2D and use contrasting colors\n",
    "    encoded_images = encoded[0].cpu().detach().numpy()\n",
    "\n",
    "encoded_data_2d = TSNE(n_components=2).fit_transform(encoded_images)\n",
    "sns.scatterplot(x=encoded_data_2d[:, 0], y=encoded_data_2d[:, 1], hue=mnist_testset.targets.numpy(), legend='full', palette=sns.color_palette(\"hls\", 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:30.427665Z",
     "start_time": "2023-10-30T11:13:30.222119Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "2hzSdX2B4aCq",
    "outputId": "fa11b182-d790-4c3b-c813-a6175aa82224",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    }
   },
   "outputs": [],
   "source": [
    "# do same with PCA\n",
    "from sklearn.decomposition import PCA\n",
    "with torch.no_grad():\n",
    "    images = mnist_trainset.data.float().unsqueeze(1)\n",
    "    images = images.to(device)\n",
    "    encoded = variational_autoencoder.encoder(images)\n",
    "\n",
    "    # Plot the encoded images in 2D and use contrasting colors\n",
    "    encoded_images = encoded[0].cpu().detach().numpy()\n",
    "\n",
    "encoded_data_2d = PCA(n_components=2).fit_transform(encoded_images)\n",
    "sns.scatterplot(x=encoded_data_2d[:, 0], y=encoded_data_2d[:, 1], hue=mnist_trainset.targets.numpy(), legend='full', palette=sns.color_palette(\"hls\", 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q optuna"
   ],
   "metadata": {
    "id": "fCWOicPY4wDo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:30.595882Z",
     "start_time": "2023-10-30T11:13:30.427855Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "JU3wBbXC4aCq"
   },
   "outputs": [],
   "source": [
    "# lets use optuna to find the best hyperparameters\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "def define_model(trial):\n",
    "    # create the Variational Autoencoder\n",
    "    hidden_dim = 256\n",
    "    latent_size = trial.suggest_int('latent_size', 2, 200)\n",
    "\n",
    "    model = VariationalAutoEncoder(input_dim=1,hidden_dim=hidden_dim, latent_dim=latent_size)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(device)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\"])\n",
    "\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    k1 =1\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    k2 = trial.suggest_float('k2', 1e-5, 1)\n",
    "    # Training of the model.\n",
    "    for epoch in range(20):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for images, _ in mnist_trainloader:\n",
    "            images = images.to(device)\n",
    "            x, mu, sigma, original_x = model(images)\n",
    "            original_x = original_x.detach()\n",
    "            loss = loss_function(x, original_x, mu, sigma,k1=k1,k2=k2)\n",
    "\n",
    "            epoch_loss += loss.mean().item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        trial.report(epoch_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return epoch_loss/len(mnist_trainloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T11:13:53.950983Z",
     "start_time": "2023-10-30T11:13:30.597480Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "mUNUWUcP4aCq",
    "outputId": "ef71a1e2-a99b-47e6-fbc3-743148ed5f80",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=1000, timeout=600)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
